{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b00dae2-c271-4a69-a579-742e084a9058",
   "metadata": {},
   "source": [
    "# Lab | Langchain Evaluation\n",
    "\n",
    "## Intro\n",
    "\n",
    "Pick different sets of data and re-run this notebook. The point is for you to understand all steps involve and the many different ways one can and should evaluate LLM applications.\n",
    "\n",
    "What did you learn? - Let's discuss that in class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "## LangChain: Evaluation\n",
    "\n",
    "### Outline:\n",
    "\n",
    "* Example generation\n",
    "* Manual evaluation (and debuging)\n",
    "* LLM-assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e29d2c-ba67-4cba-8ded-375fe040b9ba",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28008949",
   "metadata": {},
   "source": [
    "#### Create our QandA application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import CSVLoader, TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec1106d",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = 'data/OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550eb642-c223-4d78-8f92-0f265ef78b86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.34.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting tqdm (from sentence-transformers)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting numpy (from sentence-transformers)\n",
      "  Downloading numpy-2.0.0-cp311-cp311-macosx_14_0_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.14.0-cp311-cp311-macosx_14_0_x86_64.whl (25.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.5/25.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.15.1 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-10.4.0-cp311-cp311-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging>=20.9 (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.1 (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-macosx_10_9_x86_64.whl (187 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.9/187.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting sympy (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.13.0-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy (from sentence-transformers)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Downloading regex-2024.5.15-cp311-cp311-macosx_10_9_x86_64.whl (281 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.7/281.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.3-cp311-cp311-macosx_10_12_x86_64.whl (415 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.3/415.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-macosx_10_12_x86_64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_x86_64.whl (14 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-macosx_10_9_x86_64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5 (from requests->huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1 (from requests->huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests->huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, urllib3, typing-extensions, tqdm, threadpoolctl, sympy, safetensors, regex, pyyaml, Pillow, packaging, numpy, networkx, MarkupSafe, joblib, idna, fsspec, filelock, charset-normalizer, certifi, scipy, requests, jinja2, torch, scikit-learn, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: mpmath\n",
      "    Found existing installation: mpmath 1.3.0\n",
      "    Uninstalling mpmath-1.3.0:\n",
      "      Successfully uninstalled mpmath-1.3.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.19\n",
      "    Uninstalling urllib3-1.26.19:\n",
      "      Successfully uninstalled urllib3-1.26.19\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.4\n",
      "    Uninstalling tqdm-4.66.4:\n",
      "      Successfully uninstalled tqdm-4.66.4\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.5.0\n",
      "    Uninstalling threadpoolctl-3.5.0:\n",
      "      Successfully uninstalled threadpoolctl-3.5.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.0\n",
      "    Uninstalling sympy-1.13.0:\n",
      "      Successfully uninstalled sympy-1.13.0\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.4.3\n",
      "    Uninstalling safetensors-0.4.3:\n",
      "      Successfully uninstalled safetensors-0.4.3\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.5.15\n",
      "    Uninstalling regex-2024.5.15:\n",
      "      Successfully uninstalled regex-2024.5.15\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: pillow 10.4.0\n",
      "    Uninstalling pillow-10.4.0:\n",
      "      Successfully uninstalled pillow-10.4.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.3\n",
      "    Uninstalling networkx-3.3:\n",
      "      Successfully uninstalled networkx-3.3\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.5\n",
      "    Uninstalling MarkupSafe-2.1.5:\n",
      "      Successfully uninstalled MarkupSafe-2.1.5\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.4.2\n",
      "    Uninstalling joblib-1.4.2:\n",
      "      Successfully uninstalled joblib-1.4.2\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.7\n",
      "    Uninstalling idna-3.7:\n",
      "      Successfully uninstalled idna-3.7\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.5.0\n",
      "    Uninstalling fsspec-2024.5.0:\n",
      "      Successfully uninstalled fsspec-2024.5.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.15.4\n",
      "    Uninstalling filelock-3.15.4:\n",
      "      Successfully uninstalled filelock-3.15.4\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.2\n",
      "    Uninstalling charset-normalizer-3.3.2:\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.7.4\n",
      "    Uninstalling certifi-2024.7.4:\n",
      "      Successfully uninstalled certifi-2024.7.4\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.0\n",
      "    Uninstalling scipy-1.14.0:\n",
      "      Successfully uninstalled scipy-1.14.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.4\n",
      "    Uninstalling Jinja2-3.1.4:\n",
      "      Successfully uninstalled Jinja2-3.1.4\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.1\n",
      "    Uninstalling scikit-learn-1.5.1:\n",
      "      Successfully uninstalled scikit-learn-1.5.1\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.23.4\n",
      "    Uninstalling huggingface-hub-0.23.4:\n",
      "      Successfully uninstalled huggingface-hub-0.23.4\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.42.4\n",
      "    Uninstalling transformers-4.42.4:\n",
      "      Successfully uninstalled transformers-4.42.4\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 3.0.1\n",
      "    Uninstalling sentence-transformers-3.0.1:\n",
      "      Successfully uninstalled sentence-transformers-3.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "steamship 2.17.34 requires requests~=2.28.1, but you have requests 2.32.3 which is incompatible.\n",
      "steamship 2.17.34 requires tiktoken~=0.4.0, but you have tiktoken 0.7.0 which is incompatible.\n",
      "datasets 2.20.0 requires fsspec[http]<=2024.5.0,>=2023.1.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 Pillow-10.4.0 certifi-2024.7.4 charset-normalizer-3.3.2 filelock-3.15.4 fsspec-2024.6.1 huggingface-hub-0.23.4 idna-3.7 jinja2-3.1.4 joblib-1.4.2 mpmath-1.3.0 networkx-3.3 numpy-1.26.4 packaging-24.1 pyyaml-6.0.1 regex-2024.5.15 requests-2.32.3 safetensors-0.4.3 scikit-learn-1.5.1 scipy-1.14.0 sentence-transformers-3.0.1 sympy-1.13.0 threadpoolctl-3.5.0 tokenizers-0.19.1 torch-2.2.2 tqdm-4.66.4 transformers-4.42.4 typing-extensions-4.12.2 urllib3-2.2.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31c218f",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\", model_kwargs = {'device': 'cpu'})\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2006054",
   "metadata": {
    "height": 183,
    "tags": []
   },
   "source": [
    "llm = ChatOpenAI(temperature = 0.0)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    verbose=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ebd73",
   "metadata": {},
   "source": [
    "#### Coming up with test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb04a0f9",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data/OutdoorClothingCatalog_1000.csv', 'row': 10}, page_content=\": 10\\nname: Cozy Comfort Pullover Set, Stripe\\ndescription: Perfect for lounging, this striped knit set lives up to its name. We used ultrasoft fabric and an easy design that's as comfortable at bedtime as it is when we have to make a quick run out.\\n\\nSize & Fit\\n- Pants are Favorite Fit: Sits lower on the waist.\\n- Relaxed Fit: Our most generous fit sits farthest from the body.\\n\\nFabric & Care\\n- In the softest blend of 63% polyester, 35% rayon and 2% spandex.\\n\\nAdditional Features\\n- Relaxed fit top with raglan sleeves and rounded hem.\\n- Pull-on pants have a wide elastic waistband and drawstring, side pockets and a modern slim leg.\\n\\nImported.\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe4a88c2",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=': 11\\nname: Ultra-Lofty 850 Stretch Down Hooded Jacket\\ndescription: This technical stretch down jacket from our DownTek collection is sure to keep you warm and comfortable with its full-stretch construction providing exceptional range of motion. With a slightly fitted style that falls at the hip and best with a midweight layer, this jacket is suitable for light activity up to 20° and moderate activity up to -30°. The soft and durable 100% polyester shell offers complete windproof protection and is insulated with warm, lofty goose down. Other features include welded baffles for a no-stitch construction and excellent stretch, an adjustable hood, an interior media port and mesh stash pocket and a hem drawcord. Machine wash and dry. Imported.', metadata={'source': '../data/OutdoorClothingCatalog_1000.csv', 'row': 11})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d548aef",
   "metadata": {},
   "source": [
    "#### Hard-coded examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106fbd91-f7bc-4d6b-b090-54b6a485ce39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c5d5af6-36db-4421-b635-46384e677847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer='Yes, it is available in three colors: grey, navy, and black.'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Do the Cozy Comfort Pullover Set\\\n",
    "        have side pockets?\",\n",
    "        \"answer\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What collection is the Ultra-Lofty \\\n",
    "        850 Stretch Down Hooded Jacket from?\",\n",
    "        \"answer\": \"The DownTek collection\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"Examples:\\n\"\n",
    "             \"1. Query: Do the Cozy Comfort Pullover Set have side pockets?\\n\"\n",
    "             \"   Answer: Yes\\n\"\n",
    "             \"2. Query: What collection is the Ultra-Lofty 850 Stretch Down Hooded Jacket from?\\n\"\n",
    "             \"   Answer: The DownTek collection\\n\"\n",
    "             \"Query: {query}\\n\"\n",
    "             \"Answer:\"\n",
    ")\n",
    "\n",
    "# Define the output model\n",
    "class Answer(BaseModel):\n",
    "    answer: str = Field(description=\"The answer to the query\")\n",
    "\n",
    "# Create the output parser\n",
    "class AnswerOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str) -> Answer:\n",
    "        # Split the response to get the answer\n",
    "        answer = text.strip().split(\"Answer:\")[-1].strip()\n",
    "        return Answer(answer=answer)\n",
    "\n",
    "# Initialize the LLM\n",
    "# llm = OpenAI()\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# Create the LLMChain\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    output_parser=AnswerOutputParser()\n",
    ")\n",
    "\n",
    "# Example query\n",
    "query = \"Is the Cozy Comfort Pullover Set available in different colors?\"\n",
    "\n",
    "# Run the chain\n",
    "result = llm_chain.run({\"query\": query})\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ce3e4f",
   "metadata": {},
   "source": [
    "#### LLM-Generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d44f8376",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34e87816",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acb34772-368f-4b5e-b4bd-da9b637cc7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62abae09",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages/langchain/chains/llm.py:369: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97ab28b5",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qa_pairs': {'query': \"What is the approximate weight of the Women's Campside Oxfords per pair?\",\n",
       "  'answer': \"The approximate weight of the Women's Campside Oxfords per pair is 1 lb. 1 oz.\"}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ebe4228",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data/OutdoorClothingCatalog_1000.csv', 'row': 0}, page_content=\": 0\\nname: Women's Campside Oxfords\\ndescription: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \\n\\nSize & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \\n\\nSpecs: Approx. weight: 1 lb.1 oz. per pair. \\n\\nConstruction: Soft canvas material for a broken-in feel and look. Comfortable EVA innersole with Cleansport NXT® antimicrobial odor control. Vintage hunt, fish and camping motif on innersole. Moderate arch contour of innersole. EVA foam midsole for cushioning and support. Chain-tread-inspired molded rubber outsole with modified chain-tread pattern. Imported. \\n\\nQuestions? Please contact us for any inquiries.\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7693fe86-feeb-4d73-b400-e66e79315274",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': \"What is the approximate weight of the Women's Campside Oxfords per pair?\",\n",
       "  'answer': \"The approximate weight of the Women's Campside Oxfords per pair is 1 lb. 1 oz.\"},\n",
       " {'query': 'What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat, Chevron Weave?',\n",
       "  'answer': 'The small size of the Recycled Waterhog Dog Mat, Chevron Weave has dimensions of 18\" x 28\", while the medium size has dimensions of 22.5\" x 34.5\".'},\n",
       " {'query': \"What features does the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offer for sun protection and secure fit?\",\n",
       "  'answer': \"The swimsuit offers UPF 50+ rated fabric for the highest sun protection, blocking 98% of the sun's harmful rays. It also has crossover no-slip straps and a fully lined bottom to ensure a secure fit and maximum coverage.\"},\n",
       " {'query': 'What is the fabric composition of the Refresh Swimwear V-Neck Tankini Contrasts top?',\n",
       "  'answer': 'The body of the tankini top is made of 82% recycled nylon and 18% Lycra® spandex, while the lining is made of 90% recycled nylon and 10% Lycra® spandex.'},\n",
       " {'query': 'What type of technology is used in the EcoFlex 3L Storm Pants to make them more breathable?',\n",
       "  'answer': 'The EcoFlex 3L Storm Pants use TEK O2 technology to make them more breathable.'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_flattened = [data['qa_pairs'] for data in new_examples]\n",
    "d_flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf25f2f",
   "metadata": {},
   "source": [
    "#### Combine examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ada2a3fc",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# examples += new_example\n",
    "examples += d_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2184b9d7-22ab-43a5-9ba5-b27fef024874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Do the Cozy Comfort Pullover Set        have side pockets?',\n",
       " 'answer': 'Yes'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cdf5cf5",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Do the Cozy Comfort Pullover Set        have side pockets?',\n",
       " 'text': 'Yes, the Cozy Comfort Pullover Set does have side pockets.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3cb08",
   "metadata": {},
   "source": [
    "### Manual Evaluation - Fun part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcaf622e",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a142638",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Do the Cozy Comfort Pullover Set        have side pockets?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Examples:\\n1. Query: Do the Cozy Comfort Pullover Set have side pockets?\\n   Answer: Yes\\n2. Query: What collection is the Ultra-Lofty 850 Stretch Down Hooded Jacket from?\\n   Answer: The DownTek collection\\nQuery: Do the Cozy Comfort Pullover Set        have side pockets?\\nAnswer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LLMChain > llm:ChatOpenAI] [1.14s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, the Cozy Comfort Pullover Set does have side pockets.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, the Cozy Comfort Pullover Set does have side pockets.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 14,\n",
      "                \"prompt_tokens\": 76,\n",
      "                \"total_tokens\": 90\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-415ed1e9-f68e-4ec9-8cb2-50d0982af5cd-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 76,\n",
      "              \"output_tokens\": 14,\n",
      "              \"total_tokens\": 90\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 14,\n",
      "      \"prompt_tokens\": 76,\n",
      "      \"total_tokens\": 90\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LLMChain] [1.15s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Yes, the Cozy Comfort Pullover Set does have side pockets.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Do the Cozy Comfort Pullover Set        have side pockets?',\n",
       " 'text': 'Yes, the Cozy Comfort Pullover Set does have side pockets.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3d6bef0",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn off the debug mode\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bdbdce",
   "metadata": {},
   "source": [
    "### LLM assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a54769b0-3daf-4cac-b259-89a10dd9b5a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples += d_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ea95385-1b4c-440a-9fea-8500b4cc2154",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Do the Cozy Comfort Pullover Set        have side pockets?',\n",
       "  'answer': 'Yes'},\n",
       " {'query': 'What collection is the Ultra-Lofty         850 Stretch Down Hooded Jacket from?',\n",
       "  'answer': 'The DownTek collection'},\n",
       " {'query': \"What is the approximate weight of the Women's Campside Oxfords per pair?\",\n",
       "  'answer': \"The approximate weight of the Women's Campside Oxfords per pair is 1 lb. 1 oz.\"},\n",
       " {'query': 'What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat, Chevron Weave?',\n",
       "  'answer': 'The small size of the Recycled Waterhog Dog Mat, Chevron Weave has dimensions of 18\" x 28\", while the medium size has dimensions of 22.5\" x 34.5\".'},\n",
       " {'query': \"What features does the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offer for sun protection and secure fit?\",\n",
       "  'answer': \"The swimsuit offers UPF 50+ rated fabric for the highest sun protection, blocking 98% of the sun's harmful rays. It also has crossover no-slip straps and a fully lined bottom to ensure a secure fit and maximum coverage.\"},\n",
       " {'query': 'What is the fabric composition of the Refresh Swimwear V-Neck Tankini Contrasts top?',\n",
       "  'answer': 'The body of the tankini top is made of 82% recycled nylon and 18% Lycra® spandex, while the lining is made of 90% recycled nylon and 10% Lycra® spandex.'},\n",
       " {'query': 'What type of technology is used in the EcoFlex 3L Storm Pants to make them more breathable?',\n",
       "  'answer': 'The EcoFlex 3L Storm Pants use TEK O2 technology to make them more breathable.'},\n",
       " {'query': \"What is the approximate weight of the Women's Campside Oxfords per pair?\",\n",
       "  'answer': \"The approximate weight of the Women's Campside Oxfords per pair is 1 lb. 1 oz.\"},\n",
       " {'query': 'What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat, Chevron Weave?',\n",
       "  'answer': 'The small size of the Recycled Waterhog Dog Mat, Chevron Weave has dimensions of 18\" x 28\", while the medium size has dimensions of 22.5\" x 34.5\".'},\n",
       " {'query': \"What features does the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offer for sun protection and secure fit?\",\n",
       "  'answer': \"The swimsuit offers UPF 50+ rated fabric for the highest sun protection, blocking 98% of the sun's harmful rays. It also has crossover no-slip straps and a fully lined bottom to ensure a secure fit and maximum coverage.\"},\n",
       " {'query': 'What is the fabric composition of the Refresh Swimwear V-Neck Tankini Contrasts top?',\n",
       "  'answer': 'The body of the tankini top is made of 82% recycled nylon and 18% Lycra® spandex, while the lining is made of 90% recycled nylon and 10% Lycra® spandex.'},\n",
       " {'query': 'What type of technology is used in the EcoFlex 3L Storm Pants to make them more breathable?',\n",
       "  'answer': 'The EcoFlex 3L Storm Pants use TEK O2 technology to make them more breathable.'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4dca05a",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = llm_chain.batch(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae7e8b4e-4468-4048-8544-c9936704ea93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Do the Cozy Comfort Pullover Set        have side pockets?',\n",
       "  'answer': 'Yes',\n",
       "  'text': 'Yes, the Cozy Comfort Pullover Set has side pockets.'},\n",
       " {'query': 'What collection is the Ultra-Lofty         850 Stretch Down Hooded Jacket from?',\n",
       "  'answer': 'The DownTek collection',\n",
       "  'text': 'The DownTek collection'},\n",
       " {'query': \"What is the approximate weight of the Women's Campside Oxfords per pair?\",\n",
       "  'answer': \"The approximate weight of the Women's Campside Oxfords per pair is 1 lb. 1 oz.\",\n",
       "  'text': \"The approximate weight of the Women's Campside Oxfords per pair is 1 lb 5 oz.\"},\n",
       " {'query': 'What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat, Chevron Weave?',\n",
       "  'answer': 'The small size of the Recycled Waterhog Dog Mat, Chevron Weave has dimensions of 18\" x 28\", while the medium size has dimensions of 22.5\" x 34.5\".',\n",
       "  'text': 'The small size measures 18\" x 28\" and the medium size measures 27\" x 45\".'},\n",
       " {'query': \"What features does the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offer for sun protection and secure fit?\",\n",
       "  'answer': \"The swimsuit offers UPF 50+ rated fabric for the highest sun protection, blocking 98% of the sun's harmful rays. It also has crossover no-slip straps and a fully lined bottom to ensure a secure fit and maximum coverage.\",\n",
       "  'text': 'The swimsuit offers UPF 50+ sun protection and features adjustable straps for a secure fit.'},\n",
       " {'query': 'What is the fabric composition of the Refresh Swimwear V-Neck Tankini Contrasts top?',\n",
       "  'answer': 'The body of the tankini top is made of 82% recycled nylon and 18% Lycra® spandex, while the lining is made of 90% recycled nylon and 10% Lycra® spandex.',\n",
       "  'text': 'The fabric composition of the Refresh Swimwear V-Neck Tankini Contrasts top is 82% Nylon and 18% Spandex.'},\n",
       " {'query': 'What type of technology is used in the EcoFlex 3L Storm Pants to make them more breathable?',\n",
       "  'answer': 'The EcoFlex 3L Storm Pants use TEK O2 technology to make them more breathable.',\n",
       "  'text': 'GORE-TEX technology'},\n",
       " {'query': \"What is the approximate weight of the Women's Campside Oxfords per pair?\",\n",
       "  'answer': \"The approximate weight of the Women's Campside Oxfords per pair is 1 lb. 1 oz.\",\n",
       "  'text': '3. Answer: Approximately 1lb 8oz per pair'},\n",
       " {'query': 'What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat, Chevron Weave?',\n",
       "  'answer': 'The small size of the Recycled Waterhog Dog Mat, Chevron Weave has dimensions of 18\" x 28\", while the medium size has dimensions of 22.5\" x 34.5\".',\n",
       "  'text': 'The small size is 18\" x 26\" and the medium size is 20\" x 30\".'},\n",
       " {'query': \"What features does the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offer for sun protection and secure fit?\",\n",
       "  'answer': \"The swimsuit offers UPF 50+ rated fabric for the highest sun protection, blocking 98% of the sun's harmful rays. It also has crossover no-slip straps and a fully lined bottom to ensure a secure fit and maximum coverage.\",\n",
       "  'text': 'The swimsuit offers UPF 50+ sun protection and adjustable straps for a secure fit.'},\n",
       " {'query': 'What is the fabric composition of the Refresh Swimwear V-Neck Tankini Contrasts top?',\n",
       "  'answer': 'The body of the tankini top is made of 82% recycled nylon and 18% Lycra® spandex, while the lining is made of 90% recycled nylon and 10% Lycra® spandex.',\n",
       "  'text': 'The fabric composition of the Refresh Swimwear V-Neck Tankini Contrasts top is 82% nylon and 18% spandex.'},\n",
       " {'query': 'What type of technology is used in the EcoFlex 3L Storm Pants to make them more breathable?',\n",
       "  'answer': 'The EcoFlex 3L Storm Pants use TEK O2 technology to make them more breathable.',\n",
       "  'text': 'EcoFlex technology'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6012a3e0",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "724b1c0b",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b46ae55",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "graded_outputs = eval_chain.evaluate(examples, predictions, prediction_key=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc42eb35-c2d7-4581-8004-d315ade63eef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'results': 'CORRECT'}, {'results': 'CORRECT'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3437cfbe",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: Do the Cozy Comfort Pullover Set        have side pockets?\n",
      "Real Answer: Yes\n",
      "Predicted Answer: Yes, the Cozy Comfort Pullover Set has side pockets.\n",
      "\n",
      "Example 1:\n",
      "Question: What collection is the Ultra-Lofty         850 Stretch Down Hooded Jacket from?\n",
      "Real Answer: The DownTek collection\n",
      "Predicted Answer: The DownTek collection\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['text'])\n",
    "    # print(\"Predicted Grade: \" + graded_outputs[i]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721d127a-a9e3-465d-a8ae-0e2c4b4a2659",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "One can also easily evaluate your QA chains with the metrics offered in ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a5ef0493-34ff-4801-b405-69c76ce86c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages/langchain/indexes/vectorstore.py:129: UserWarning: Using InMemoryVectorStore as the default vectorstore.This memory store won't persist data. You should explicitlyspecify a vectorstore when using VectorstoreIndexCreator\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "loader = TextLoader(\"data/nyc_text.txt\")\n",
    "index = VectorstoreIndexCreator(embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\", model_kwargs = {'device': 'mps'})).from_loaders([loader])\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature= 0)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=index.vectorstore.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0449cae-de25-4ef6-ae64-78ccf5e06a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York City was originally named New Amsterdam by Dutch colonists in 1626. When the city came under British control in 1664, it was renamed New York after King Charles II of England granted the lands to his brother, the Duke of York. The city has been continuously named New York since November 1674.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing it out\n",
    "\n",
    "question = \"How did New York City get its name?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e846b3d-f79f-46eb-8075-c816268c0500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'How did New York City get its name?',\n",
       " 'result': 'New York City was originally named New Amsterdam by Dutch colonists in 1626. When the city came under British control in 1664, it was renamed New York after King Charles II of England granted the lands to his brother, the Duke of York. The city has been continuously named New York since November 1674.',\n",
       " 'source_documents': [Document(id='62d3f48d-89f2-4399-9f3e-689eeb45df58', metadata={'source': 'data/nyc_text.txt'}, page_content='The city and its metropolitan area constitute the premier gateway for legal immigration to the United States. As many as 800 languages are spoken in New York, making it the most linguistically diverse city in the world. New York City is home to more than 3.2 million residents born outside the U.S., the largest foreign-born population of any city in the world as of 2016.New York City traces its origins to a trading post founded on the southern tip of Manhattan Island by Dutch colonists in approximately 1624. The settlement was named New Amsterdam (Dutch: Nieuw Amsterdam) in 1626 and was chartered as a city in 1653. The city came under British control in 1664 and was renamed New York after King Charles II of England granted the lands to his brother, the Duke of York. The city was regained by the Dutch in July 1673 and was renamed New Orange for one year and three months; the city has been continuously named New York since November 1674. New York City was the capital of the United States'),\n",
       "  Document(id='12e68176-5869-4d6e-818e-3684e550a703', metadata={'source': 'data/nyc_text.txt'}, page_content='New York City has been a metropolitan municipality with a Strong mayor–council form of government since its consolidation in 1898. In New York City, the city government is responsible for public education, correctional institutions, public safety, recreational facilities, sanitation, water supply, and welfare services.'),\n",
       "  Document(id='118add65-6770-4dd4-b952-e064f5d97eda', metadata={'source': 'data/nyc_text.txt'}, page_content=\"Despite New York's heavy reliance on its vast public transit system, streets are a defining feature of the city. The Commissioners' Plan of 1811 greatly influenced the city's physical development. Several of the city's streets and avenues, including Broadway, Wall Street, Madison Avenue, and Seventh Avenue are also used as metonyms for national industries there: the theater, finance, advertising, and fashion organizations, respectively.\"),\n",
       "  Document(id='83bdfcb3-bfa4-4422-92d7-87a2579b38d9', metadata={'source': 'data/nyc_text.txt'}, page_content=\"In the pre-Columbian era, the area of present-day New York City was inhabited by Algonquian Native Americans, including the Lenape. Their homeland, known as Lenapehoking, included the present-day areas of Staten Island, Manhattan, the Bronx, the western portion of Long Island (including the areas that would later become the boroughs of Brooklyn and Queens), and the Lower Hudson Valley.The first documented visit into New York Harbor by a European was in 1524 by Italian Giovanni da Verrazzano, an explorer from Florence in the service of the French crown. He claimed the area for France and named it Nouvelle Angoulême (New Angoulême). A Spanish expedition, led by the Portuguese captain Estêvão Gomes sailing for Emperor Charles V, arrived in New York Harbor in January 1525 and charted the mouth of the Hudson River, which he named Río de San Antonio ('Saint Anthony's River'). The Padrón Real of 1527, the first scientific map to show the East Coast of North America continuously, was informed\")]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d9da8-a593-4fc6-9d4b-fea2af6bdfd0",
   "metadata": {},
   "source": [
    "Now in order to evaluate the qa system we generated a few relevant questions. We've generated a few question for you but feel free to add any you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a2e2cade-0005-41c1-b775-c6a7175bcf3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "    \"What is the population of New York City as of 2020?\",\n",
    "    \"Which borough of New York City has the highest population?\",\n",
    "    \"What is the economic significance of New York City?\",\n",
    "    \"How did New York City get its name?\",\n",
    "    \"What is the significance of the Statue of Liberty in New York City?\",\n",
    "]\n",
    "\n",
    "eval_answers = [\n",
    "    \"8,804,190\",\n",
    "    \"Brooklyn\",\n",
    "    \"New York City's economic significance is vast, as it serves as the global financial capital, housing Wall Street and major financial institutions. Its diverse economy spans technology, media, healthcare, education, and more, making it resilient to economic fluctuations. NYC is a hub for international business, attracting global companies, and boasts a large, skilled labor force. Its real estate market, tourism, cultural industries, and educational institutions further fuel its economic prowess. The city's transportation network and global influence amplify its impact on the world stage, solidifying its status as a vital economic player and cultural epicenter.\",\n",
    "    \"New York City got its name when it came under British control in 1664. King Charles II of England granted the lands to his brother, the Duke of York, who named the city New York in his own honor.\",\n",
    "    \"The Statue of Liberty in New York City holds great significance as a symbol of the United States and its ideals of liberty and peace. It greeted millions of immigrants who arrived in the U.S. by ship in the late 19th and early 20th centuries, representing hope and freedom for those seeking a better life. It has since become an iconic landmark and a global symbol of cultural diversity and freedom.\",\n",
    "]\n",
    "\n",
    "examples = [\n",
    "    {\"query\": q, \"ground_truths\": [eval_answers[i]]}\n",
    "    for i, q in enumerate(eval_questions)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aac9358e-f8bc-4992-aea3-c83160ff0ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'What is the population of New York City as of 2020?',\n",
       "  'ground_truths': ['8,804,190']},\n",
       " {'query': 'Which borough of New York City has the highest population?',\n",
       "  'ground_truths': ['Brooklyn']},\n",
       " {'query': 'What is the economic significance of New York City?',\n",
       "  'ground_truths': [\"New York City's economic significance is vast, as it serves as the global financial capital, housing Wall Street and major financial institutions. Its diverse economy spans technology, media, healthcare, education, and more, making it resilient to economic fluctuations. NYC is a hub for international business, attracting global companies, and boasts a large, skilled labor force. Its real estate market, tourism, cultural industries, and educational institutions further fuel its economic prowess. The city's transportation network and global influence amplify its impact on the world stage, solidifying its status as a vital economic player and cultural epicenter.\"]},\n",
       " {'query': 'How did New York City get its name?',\n",
       "  'ground_truths': ['New York City got its name when it came under British control in 1664. King Charles II of England granted the lands to his brother, the Duke of York, who named the city New York in his own honor.']},\n",
       " {'query': 'What is the significance of the Statue of Liberty in New York City?',\n",
       "  'ground_truths': ['The Statue of Liberty in New York City holds great significance as a symbol of the United States and its ideals of liberty and peace. It greeted millions of immigrants who arrived in the U.S. by ship in the late 19th and early 20th centuries, representing hope and freedom for those seeking a better life. It has since become an iconic landmark and a global symbol of cultural diversity and freedom.']}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a21efe8-7c30-449a-9b8e-5b79778e305b",
   "metadata": {},
   "source": [
    "#### Introducing RagasEvaluatorChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c2214-a6eb-4d4f-9403-7e1574b97a36",
   "metadata": {},
   "source": [
    "`RagasEvaluatorChain` creates a wrapper around the metrics ragas provides (documented [here](https://github.com/explodinggradients/ragas/blob/main/docs/metrics.md)), making it easier to run these evaluation with langchain and langsmith.\n",
    "\n",
    "The evaluator chain has the following APIs\n",
    "\n",
    "- `__call__()`: call the `RagasEvaluatorChain` directly on the result of a QA chain.\n",
    "- `evaluate()`: evaluate on a list of examples (with the input queries) and predictions (outputs from the QA chain). \n",
    "- `evaluate_run()`: method implemented that is called by langsmith evaluators to evaluate langsmith datasets.\n",
    "\n",
    "lets see each of them in action to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "022c8aae-fe5f-4274-b638-9209151b9491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Manhattan (New York County) has the highest population density of any borough in New York City.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain.invoke({\"query\": eval_questions[1]})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eae31c80-42c9-4b1f-95b3-c05ceadb103f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key_mapping = {\n",
    "    \"query\": \"question\",\n",
    "    \"result\": \"answer\",\n",
    "    \"source_documents\": \"contexts\"\n",
    "}\n",
    "\n",
    "result_updated = {}\n",
    "for old_key, new_key in key_mapping.items():\n",
    "    if old_key in result:\n",
    "        result_updated[new_key] = result[old_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ecd4dd9f-16d7-43d4-ac8e-6c5aa5e3f7b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How did New York City get its name?',\n",
       " 'answer': 'New York City was originally named New Amsterdam by Dutch colonists in 1626. When the city came under British control in 1664, it was renamed New York after King Charles II of England granted the lands to his brother, the Duke of York. The city has been continuously named New York since November 1674.',\n",
       " 'contexts': [Document(id='d2594319-5f93-4aec-94e1-34291a237a2b', metadata={'source': 'data/nyc_text.txt'}, page_content='The city and its metropolitan area constitute the premier gateway for legal immigration to the United States. As many as 800 languages are spoken in New York, making it the most linguistically diverse city in the world. New York City is home to more than 3.2 million residents born outside the U.S., the largest foreign-born population of any city in the world as of 2016.New York City traces its origins to a trading post founded on the southern tip of Manhattan Island by Dutch colonists in approximately 1624. The settlement was named New Amsterdam (Dutch: Nieuw Amsterdam) in 1626 and was chartered as a city in 1653. The city came under British control in 1664 and was renamed New York after King Charles II of England granted the lands to his brother, the Duke of York. The city was regained by the Dutch in July 1673 and was renamed New Orange for one year and three months; the city has been continuously named New York since November 1674. New York City was the capital of the United States'),\n",
       "  Document(id='2dac094c-dd68-45b2-b0a2-d517a5e3f0bd', metadata={'source': 'data/nyc_text.txt'}, page_content='New York City has been a metropolitan municipality with a Strong mayor–council form of government since its consolidation in 1898. In New York City, the city government is responsible for public education, correctional institutions, public safety, recreational facilities, sanitation, water supply, and welfare services.'),\n",
       "  Document(id='4b5505ea-fc7a-4048-92f3-5616caae96fa', metadata={'source': 'data/nyc_text.txt'}, page_content=\"Despite New York's heavy reliance on its vast public transit system, streets are a defining feature of the city. The Commissioners' Plan of 1811 greatly influenced the city's physical development. Several of the city's streets and avenues, including Broadway, Wall Street, Madison Avenue, and Seventh Avenue are also used as metonyms for national industries there: the theater, finance, advertising, and fashion organizations, respectively.\"),\n",
       "  Document(id='2188fe80-9d1f-4335-829b-19bfbc6f3c67', metadata={'source': 'data/nyc_text.txt'}, page_content=\"In the pre-Columbian era, the area of present-day New York City was inhabited by Algonquian Native Americans, including the Lenape. Their homeland, known as Lenapehoking, included the present-day areas of Staten Island, Manhattan, the Bronx, the western portion of Long Island (including the areas that would later become the boroughs of Brooklyn and Queens), and the Lower Hudson Valley.The first documented visit into New York Harbor by a European was in 1524 by Italian Giovanni da Verrazzano, an explorer from Florence in the service of the French crown. He claimed the area for France and named it Nouvelle Angoulême (New Angoulême). A Spanish expedition, led by the Portuguese captain Estêvão Gomes sailing for Emperor Charles V, arrived in New York Harbor in January 1525 and charted the mouth of the Hudson River, which he named Río de San Antonio ('Saint Anthony's River'). The Padrón Real of 1527, the first scientific map to show the East Coast of North America continuously, was informed\")]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e297861",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_updated['contexts']\n",
    "contexts_str_list = []\n",
    "\n",
    "# Iterate through each Document in result_updated['contexts']\n",
    "for document in result_updated['contexts']:\n",
    "    # Append the page_content of each Document to contexts_str_list\n",
    "    contexts_str_list.append(document.page_content)\n",
    "\n",
    "# Join the list of strings with newline character\n",
    "contexts_str = \"\\n\".join(contexts_str_list)\n",
    "\n",
    "# Assign the concatenated string back to result_updated['contexts']\n",
    "result_updated['contexts'] = contexts_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00d5cc30-d25e-41bd-8695-9246b73938bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting recordclass\n",
      "  Downloading recordclass-0.22.0.3.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: recordclass\n",
      "  Building wheel for recordclass (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for recordclass: filename=recordclass-0.22.0.3-cp311-cp311-macosx_14_0_x86_64.whl size=134332 sha256=05aee638b251a4f50ed6ff9415efa9cd50e724074992d2532e9b4ecc7b1fe191\n",
      "  Stored in directory: /private/var/folders/lx/nvn9c7zn4hn_v2p5x90l_3m40000gn/T/pip-ephem-wheel-cache-bsl396ri/wheels/64/b7/44/3682fe19000959599eca91252467e45b0f4ea5f0e240bc2015\n",
      "Successfully built recordclass\n",
      "Installing collected packages: recordclass\n",
      "Successfully installed recordclass-0.22.0.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir recordclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "775d55d9-437d-40c4-bb5f-87c7b65fa567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ragas==0.1.9\n",
      "  Downloading ragas-0.1.9-py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.1/86.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from ragas==0.1.9) (1.26.4)\n",
      "Requirement already satisfied: datasets in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from ragas==0.1.9) (2.20.0)\n",
      "Requirement already satisfied: tiktoken in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from ragas==0.1.9) (0.7.0)\n",
      "Requirement already satisfied: langchain in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from ragas==0.1.9) (0.2.7)\n",
      "Requirement already satisfied: langchain-core in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from ragas==0.1.9) (0.2.12)\n",
      "Requirement already satisfied: langchain-community in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from ragas==0.1.9) (0.2.7)\n",
      "Requirement already satisfied: langchain-openai in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from ragas==0.1.9) (0.1.14)\n",
      "Requirement already satisfied: openai>1 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from ragas==0.1.9) (1.35.13)\n",
      "Collecting pysbd>=0.3.4 (from ragas==0.1.9)\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nest-asyncio in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from ragas==0.1.9) (1.6.0)\n",
      "Collecting appdirs (from ragas==0.1.9)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from openai>1->ragas==0.1.9) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from openai>1->ragas==0.1.9) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from openai>1->ragas==0.1.9) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from openai>1->ragas==0.1.9) (1.10.17)\n",
      "Requirement already satisfied: sniffio in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from openai>1->ragas==0.1.9) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from openai>1->ragas==0.1.9) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from openai>1->ragas==0.1.9) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from datasets->ragas==0.1.9) (3.15.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from datasets->ragas==0.1.9) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from datasets->ragas==0.1.9) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from datasets->ragas==0.1.9) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from datasets->ragas==0.1.9) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from datasets->ragas==0.1.9) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from datasets->ragas==0.1.9) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from datasets->ragas==0.1.9) (0.70.16)\n",
      "Collecting fsspec[http]<=2024.5.0,>=2023.1.0 (from datasets->ragas==0.1.9)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from datasets->ragas==0.1.9) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from datasets->ragas==0.1.9) (0.23.4)\n",
      "Requirement already satisfied: packaging in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from datasets->ragas==0.1.9) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from datasets->ragas==0.1.9) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from langchain->ragas==0.1.9) (2.0.31)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from langchain->ragas==0.1.9) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from langchain->ragas==0.1.9) (0.1.84)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from langchain->ragas==0.1.9) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from langchain-core->ragas==0.1.9) (1.33)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from langchain-community->ragas==0.1.9) (0.6.7)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from tiktoken->ragas==0.1.9) (2024.5.15)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.9) (23.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.9) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.9) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.9) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.9) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.9) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.9) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>1->ragas==0.1.9) (3.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.1.9) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.1.9) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.1.9) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.1.9) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas==0.1.9) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas==0.1.9) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas==0.1.9) (3.10.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from requests>=2.32.2->datasets->ragas==0.1.9) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas==0.1.9) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from pandas->datasets->ragas==0.1.9) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from pandas->datasets->ragas==0.1.9) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from pandas->datasets->ragas==0.1.9) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas==0.1.9) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.1.9) (1.0.0)\n",
      "Installing collected packages: appdirs, pysbd, fsspec, ragas\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.1\n",
      "    Uninstalling fsspec-2024.6.1:\n",
      "      Successfully uninstalled fsspec-2024.6.1\n",
      "Successfully installed appdirs-1.4.4 fsspec-2024.5.0 pysbd-0.3.4 ragas-0.1.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ragas==0.1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2c43326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in /Users/pedrorenan/.pyenv/versions/3.11.4/envs/ironhack/lib/python3.11/site-packages (1.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install  nest_asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29b14c07-bf6c-4e86-ad1a-2a6c4d1a509d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragas.integrations.langchain import EvaluatorChain \n",
    "# from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "# create evaluation chains\n",
    "faithfulness_chain   = EvaluatorChain(metric=faithfulness)\n",
    "answer_rel_chain     = EvaluatorChain(metric=answer_relevancy)\n",
    "context_rel_chain    = EvaluatorChain(metric=context_relevancy)\n",
    "context_recall_chain = EvaluatorChain(metric=context_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a8b636-d738-41bd-ac68-21cce2c4b720",
   "metadata": {},
   "source": [
    "1. `__call__()`\n",
    "\n",
    "Directly run the evaluation chain with the results from the QA chain. Do note that metrics like context_relevancy and faithfulness require the `source_documents` to be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7815671c-1fc8-46ba-8356-4a0bd5558530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Which borough of New York City has the highest population?',\n",
       " 'result': 'Manhattan (New York County) has the highest population density of any borough in New York City.',\n",
       " 'source_documents': [Document(id='45cc3296-91a4-4d26-9f00-fca7e249c36b', metadata={'source': 'data/nyc_text.txt'}, page_content=\"New York City is the most populous city in the United States, with 8,804,190 residents incorporating more immigration into the city than outmigration since the 2010 United States census. More than twice as many people live in New York City as compared to Los Angeles, the second-most populous U.S. city; and New York has more than three times the population of Chicago, the third-most populous U.S. city. New York City gained more residents between 2010 and 2020 (629,000) than any other U.S. city, and a greater amount than the total sum of the gains over the same decade of the next four largest U.S. cities, Los Angeles, Chicago, Houston, and Phoenix, Arizona combined. New York City's population is about 44% of New York State's population, and about 39% of the population of the New York metropolitan area. The majority of New York City residents in 2020 (5,141,538, or 58.4%) were living on Long Island, in Brooklyn, or in Queens. The New York City metropolitan statistical area, has the\"),\n",
       "  Document(id='b546f5dd-9ed4-4bbe-92af-ac2875bc09af', metadata={'source': 'data/nyc_text.txt'}, page_content=\"New York, often called New York City or NYC, is the most populous city in the United States. With a 2020 population of 8,804,190 distributed over 300.46 square miles (778.2 km2), New York City is the most densely populated major city in the United States and more than twice as populous as Los Angeles, the nation's second-largest city. New York City is located at the southern tip of New York State. It constitutes the geographical and demographic center of both the Northeast megalopolis and the New York metropolitan area, the largest metropolitan area in the U.S. by both population and urban area. With over 20.1 million people in its metropolitan statistical area and 23.5 million in its combined statistical area as of 2020, New York is one of the world's most populous megacities, and over 58 million people live within 250 mi (400 km) of the city. New York City is a global cultural, financial, entertainment, and media center with a significant influence on commerce, health care and life\"),\n",
       "  Document(id='5b7b41b6-8c37-47b8-9870-93bfa5063da3', metadata={'source': 'data/nyc_text.txt'}, page_content=\"Manhattan (New York County) is the geographically smallest and most densely populated borough. It is home to Central Park and most of the city's skyscrapers, and is sometimes locally known as The City. Manhattan's population density of 72,033 people per square mile (27,812/km2) in 2015 makes it the highest of any county in the United States and higher than the density of any individual American city.Manhattan is the cultural, administrative, and financial center of New York City and contains the headquarters of many major multinational corporations, the United Nations headquarters, Wall Street, and a number of important universities. The borough of Manhattan is often described as the financial and cultural center of the world.Most of the borough is situated on Manhattan Island, at the mouth of the Hudson River and the East River, and its southern tip, at the confluence of the two rivers, represents the birthplace of New York City itself. Several small islands also compose part of the\"),\n",
       "  Document(id='88522454-e3ea-495d-9a27-c39d95bfef41', metadata={'source': 'data/nyc_text.txt'}, page_content=\"=== Population density ===\\n\\nIn 2020, the city had an estimated population density of 29,302.37 inhabitants per square mile (11,313.71/km2), rendering it the nation's most densely populated of all larger municipalities (those with more than 100,000 residents), with several small cities (of fewer than 100,000) in adjacent Hudson County, New Jersey having greater density, as per the 2010 census. Geographically co-extensive with New York County, the borough of Manhattan's 2017 population density of 72,918 inhabitants per square mile (28,154/km2) makes it the highest of any county in the United States and higher than the density of any individual American city. The next three densest counties in the United States, placing second through fourth, are also New York boroughs: Brooklyn, the Bronx, and Queens respectively.\\n\\n\\n=== Race and ethnicity ===\")]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recheck the result that we are going to validate.\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfdd07c-956c-458f-8844-e056f29e3c83",
   "metadata": {},
   "source": [
    "**Faithfulness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "304f5f0f-a237-4584-becb-a35607caf26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result = faithfulness_chain(result_updated)\n",
    "eval_result[\"faithfulness\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd78a9-d7c5-42a0-8705-4c544ec6408e",
   "metadata": {},
   "source": [
    "High faithfulness_score means that there are exact consistency between the source documents and the answer.\n",
    "\n",
    "You can check lower faithfulness scores by changing the result (answer from LLM) or source_documents to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "15f42b97-a84f-4015-9da5-fa3b0b703c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_result = result_updated.copy()\n",
    "fake_result[\"result\"] = \"we are the champions\"\n",
    "fake_result[\"contexts\"] = \"Queen\"\n",
    "eval_result = faithfulness_chain(fake_result)\n",
    "eval_result[\"faithfulness\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02348380-159a-4578-a95e-493cdcfcebe7",
   "metadata": {},
   "source": [
    "**Context Relevancy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0fd2fb9e-19d1-4cf6-9773-897546c2d6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in examples:\n",
    "    if item['query'] == result_updated['question']:\n",
    "        result_updated['ground_truth'] = item['ground_truths']\n",
    "        break\n",
    "\n",
    "if 'ground_truths' in result_updated:\n",
    "    del result_updated['ground_truths']\n",
    "\n",
    "eval_result = context_recall_chain(result_updated)\n",
    "eval_result[\"context_recall\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118cba80-c2a3-408e-9d8d-857521cbe723",
   "metadata": {},
   "source": [
    "High context_recall_score means that the ground truth is present in the source documents.\n",
    "\n",
    "You can check lower context recall scores by changing the source_documents to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f6610c5f-5f8e-406c-885c-093012a5dc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "fake_result = result_updated.copy()\n",
    "fake_result[\"contexts\"] = [Document(page_content=\"I love christmas\")]\n",
    "contexts = [doc.page_content for doc in fake_result['contexts']]\n",
    "fake_result['contexts'] = contexts\n",
    "eval_result = context_recall_chain(fake_result)\n",
    "eval_result[\"context_recall\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc06403-c514-47fd-ac82-d95ece8d2f06",
   "metadata": {},
   "source": [
    "2. `evaluate()`\n",
    "\n",
    "Evaluate a list of inputs/queries and the outputs/predictions from the QA chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6b23708-b94d-4649-acd9-0e268f72f94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate method not found `faithfulness_chain`.\n"
     ]
    }
   ],
   "source": [
    "# run the queries as a batch for efficiency\n",
    "predictions = qa_chain.batch(examples)\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "\n",
    "for example in examples:\n",
    "    if 'ground_truths' in example:\n",
    "        example['answer'] = example.pop('ground_truths')\n",
    "\n",
    "# evaluate\n",
    "if hasattr(faithfulness_chain, 'evaluate'):\n",
    "    r = faithfulness_chain.evaluate(examples, predictions)\n",
    "    print(r)\n",
    "else:\n",
    "    print(\"evaluate method not found `faithfulness_chain`.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d661f6b9-04c7-40b7-874b-25f53cfab9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate method not found `context_recall_chain`.\n"
     ]
    }
   ],
   "source": [
    "# evaluate context recall\n",
    "if hasattr(context_recall_chain, 'evaluate'):\n",
    "    r = context_recall_chain.evaluate(examples, predictions)\n",
    "    print(r)\n",
    "else: \n",
    "    print(\"evaluate method not found `context_recall_chain`.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
